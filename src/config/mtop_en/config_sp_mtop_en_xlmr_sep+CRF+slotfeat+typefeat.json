{
    "dataset": "mtop",
    "debug": true,
    "task": "sp",
    "bert_model_name": "xlm-roberta-large",
    "bert_cache_dir": "./cache",
    "multi_piece_strategy": "average",
    "bert_dropout": 0.2,
    "linear_dropout": 0.2,
    "linear_bias": true,
    "linear_activation": "relu",
    "linear_hidden_num": 150,
    "use_crf": true,
    "use_type_feature": true,
	"use_pred_intent": false, 
    "use_slot_feature": true,
    "train_file": "../processed_data/mtop_en/train.json",
    "dev_file": "../processed_data/mtop_en/dev.json",
    "test_file": "../processed_data/mtop_en/test.json",
    "output_dir": "./output/sp_mtop_en_sep+CRF+slotfeat+typefeat",
    "model_type": "sep+CRF+slotfeat",
    "intent_type": "string",
    "slot_type": "string",
    "accumulate_step": 1,
    "batch_size": 16,
    "eval_batch_size": 16,
    "max_epoch": 30,
    "max_length": 60,
    "learning_rate": 0.001,
    "bert_learning_rate": 1e-05,
    "weight_decay": 0.001,
    "bert_weight_decay": 1e-05,
    "warmup_epoch": 5,
    "grad_clipping": 5.0,
    "gpu_device": 0,
    "seed": 3333
}
